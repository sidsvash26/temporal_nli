{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All imports here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, EvalPrediction \n",
    "from glue_data_huggingface import GlueDataset\n",
    "from glue_data_huggingface import GlueDataTrainingArguments as DataTrainingArguments\n",
    "from glue_processor_huggingface import glue_compute_metrics\n",
    "\n",
    "from transformers import (\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    glue_output_modes,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "from trainer_huggingface import Trainer \n",
    "\n",
    "# logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
    "    \"\"\"\n",
    "\n",
    "    model_name_or_path: str = field(\n",
    "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
    "    )\n",
    "    config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
    "    )\n",
    "    tokenizer_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
    "    )\n",
    "    cache_dir: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Where do you want to store the pretrained models downloaded from s3\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p: EvalPrediction) -> Dict:\n",
    "    '''\n",
    "    Task specific way of computing metrics\n",
    "    '''\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    \n",
    "    return glue_compute_metrics('dnc2', preds, p.label_ids)\n",
    "\n",
    "def str2bool(v):\n",
    "    return v.lower() in (\"yes\", \"true\", \"t\", \"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load roberta-large-mnli and load trainer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/data/sid/temporal_nli/data/\"\n",
    "model_dir = \"/data/sid/temporal_nli/saved_models/roberta-large/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_predictions(dev_file, \n",
    "                                test_file,\n",
    "                                model_path,\n",
    "                                dev_dir = \"../../../data/dev/\",\n",
    "                                test_dir = \"../../../data/test/\",\n",
    "                                hypo_only=False,\n",
    "                            results_location=\"results/\"):\n",
    "    '''\n",
    "    Given model path, make predictions json file for dev and test\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dev_file: Name of the dev dataset tsv file\n",
    "    test_file: Name of the test dataset tsv file\n",
    "    model_path: Directory location of the model path. Directory contains\n",
    "                pytorch_model.bin, config.json etc.\n",
    "    dev_dir: directory location of dev dataset\n",
    "    test_dir: directory location of test dataset\n",
    "    hypo_only: Boolean for whether it is a hpothesis_only model\n",
    "    results_location: Directory location where results are to be stored\n",
    "    '''\n",
    "    os.makedirs(results_location, exist_ok=True)\n",
    "    \n",
    "    model_args = ModelArguments(model_name_or_path=model_path)\n",
    "    num_labels=2\n",
    "    print(f\"Model path: {model_path}\")\n",
    "\n",
    "    ## Load configs, tokenizer, model\n",
    "    config = AutoConfig.from_pretrained(\n",
    "                    model_args.model_name_or_path,\n",
    "                    num_labels=num_labels,\n",
    "                    finetuning_task=\"dnc2\",)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "                model_args.model_name_or_path,)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "                    model_args.model_name_or_path,\n",
    "                    config=config,)\n",
    "    \n",
    "    ## Dummy training Arguments -- not relevant for predictions\n",
    "    training_args = TrainingArguments(output_dir = \".models/model_name/\",\n",
    "                                 save_total_limit=8,\n",
    "                                  per_gpu_eval_batch_size=128,\n",
    "                                 )\n",
    "    \n",
    "    ## Initialize dummy trainer\n",
    "    trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=None,\n",
    "            eval_dataset=None,\n",
    "            compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "\n",
    "    ### Load datasets\n",
    "    # Extract features from dataset\n",
    "    dev_args = DataTrainingArguments(task_name=\"dnc2\", data_dir=dev_dir)\n",
    "    test_args = DataTrainingArguments(task_name=\"dnc2\", data_dir=test_dir)\n",
    "    \n",
    "    dev_dataset = GlueDataset(dev_args, data_filename=dev_file,\n",
    "                               num_labels = num_labels,\n",
    "                               tokenizer=tokenizer,\n",
    "                              hypothesis_only=hypo_only)\n",
    "\n",
    "    test_dataset = GlueDataset(test_args, data_filename=test_file,\n",
    "                               num_labels = num_labels,\n",
    "                               tokenizer=tokenizer,\n",
    "                              hypothesis_only=hypo_only)\n",
    "\n",
    "    ### Predictions\n",
    "    dev_preds = trainer.predict(dev_dataset)\n",
    "    test_preds = trainer.predict(test_dataset)\n",
    "    \n",
    "    pred_dict = {0: 'not-entailed', 1:'entailed'}\n",
    "    \n",
    "    results_filename = model_args.model_name_or_path.split(\"/\")[-3] + \"--\" + model_args.model_name_or_path.split(\"/\")[-2]\n",
    "    \n",
    "    ## Dev\n",
    "    df_dev = pd.read_csv(dev_args.data_dir + dev_file, sep='\\t')\n",
    "    df_dev['predicted_label'] = [pred_dict[x] for x in np.argmax(dev_preds[0], axis=1)]\n",
    "    df_dev = df_dev.rename(columns={'label': 'true_label'})\n",
    "    \n",
    "    ## Test\n",
    "    df_test = pd.read_csv(test_args.data_dir + test_file, sep='\\t')\n",
    "    df_test['predicted_label'] = [pred_dict[x] for x in np.argmax(test_preds[0], axis=1)]\n",
    "    df_test = df_test.rename(columns={'label': 'true_label'})\n",
    "    \n",
    "    ### JSON Files\n",
    "    ## Dev\n",
    "    with open(\"results/\" + results_filename + \"--dev.json\", \"w\") as f1:\n",
    "        json.dump(df_dev.to_dict(orient='index'), f1, indent=4)\n",
    "        \n",
    "    ## Test\n",
    "    with open(\"results/\" + results_filename + \"--test.json\", \"w\") as f1:\n",
    "        json.dump(df_test.to_dict(orient='index'), f1, indent=4)\n",
    "        \n",
    "    ### TXT files metrics\n",
    "    ## Dev\n",
    "    with open(\"results/\" + results_filename + \"--dev.txt\", \"w\") as f1:\n",
    "        json.dump(dev_preds.metrics, f1, indent=4)\n",
    "        \n",
    "    ## Test\n",
    "    with open(\"results/\" + results_filename + \"--test.txt\", \"w\") as f1:\n",
    "        json.dump(test_preds.metrics, f1, indent=4)\n",
    "    \n",
    "    print(f\"dev metrics: {dev_preds.metrics}\")\n",
    "    print(f\"test metrics: {test_preds.metrics}\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duration Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo_true = \"../../../saved_models/roberta-large/roberta-large_uds_dur_lr_2e-05_wt_0.1_ws_122_hypo_only_True/checkpoint-13500/\"\n",
    "hypo_false = \"../../../saved_models/roberta-large/roberta-large_uds_dur_lr_2e-05_wt_0.1_ws_122_hypo_only_False/checkpoint-6000/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are instantiating a Trainer but Tensorboard is not installed. You should consider installing it.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1de6a78b93b48b49659930b0b9ed540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=90.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidvash/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db229d36c4484f61a46174b03cc0a225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=83.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dev metrics: {'eval_loss': 0.2747830780016051, 'eval_acc': 0.9164489345642455}\n",
      "test metrics: {'eval_loss': 0.2740151848060539, 'eval_acc': 0.915206881396371}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are instantiating a Trainer but Tensorboard is not installed. You should consider installing it.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343ad2b26f7a484ba86cfabffe43f760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=90.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f6a871aafb6436ba439626349678755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=83.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dev metrics: {'eval_loss': 0.2854851828681098, 'eval_acc': 0.9115136735760321}\n",
      "test metrics: {'eval_loss': 0.2780875858054104, 'eval_acc': 0.9161800715765681}\n"
     ]
    }
   ],
   "source": [
    "## Hypo_True\n",
    "save_model_predictions(\"dev-temporal-duration-data.tsv\", \n",
    "                        \"test-temporal-duration-data.tsv\",\n",
    "                        hypo_true,\n",
    "                       hypo_only=True,\n",
    "                        dev_dir = \"../../../data/dev/\",\n",
    "                        test_dir = \"../../../data/test/\",\n",
    "                        results_location=\"results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path: ../../../saved_models/roberta-large/roberta-large_uds_dur_lr_2e-05_wt_0.1_ws_122_hypo_only_False/checkpoint-6000/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are instantiating a Trainer but Tensorboard is not installed. You should consider installing it.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ad41fa78bb432e8c6d971413d8b358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=90.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidvash/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd80d1c72364354806a346567130c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=83.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dev metrics: {'eval_loss': 0.2412004096640481, 'eval_acc': 0.9358706381002149}\n",
      "test metrics: {'eval_loss': 0.2266090050878295, 'eval_acc': 0.94506184466629}\n"
     ]
    }
   ],
   "source": [
    "## Hypo_False\n",
    "save_model_predictions(\"dev-temporal-duration-data.tsv\", \n",
    "                        \"test-temporal-duration-data.tsv\",\n",
    "                        hypo_false,\n",
    "                        hypo_only=False,\n",
    "                        dev_dir = \"../../../data/dev/\",\n",
    "                        test_dir = \"../../../data/test/\",\n",
    "                        results_location=\"results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UDS-Rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo_true = \"../../../saved_models/roberta-large/roberta-large_uds_rel_lr_2e-05_wt_0.1_ws_122_hypo_only_True/checkpoint-5000/\"\n",
    "hypo_false = \"../../../saved_models/roberta-large/roberta-large_uds_rel_lr_2e-05_wt_0.1_ws_122_hypo_only_False/checkpoint-10000/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path: ../../../saved_models/roberta-large/roberta-large_uds_rel_lr_2e-05_wt_0.1_ws_122_hypo_only_True/checkpoint-5000/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are instantiating a Trainer but Tensorboard is not installed. You should consider installing it.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b759203ebf744fc82b1df2df341cdf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=118.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidvash/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e21686aee242579ea1dc175570a6d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=108.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dev metrics: {'eval_loss': 0.5408071516934088, 'eval_acc': 0.7227962043277758}\n",
      "test metrics: {'eval_loss': 0.5565330493781302, 'eval_acc': 0.7122347673739536}\n",
      "Model path: ../../../saved_models/roberta-large/roberta-large_uds_rel_lr_2e-05_wt_0.1_ws_122_hypo_only_False/checkpoint-10000/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are instantiating a Trainer but Tensorboard is not installed. You should consider installing it.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b2ef961cde45a9a38a1ea34e370cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=118.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce5e3b9dd274d639c6ecdacaf295024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=108.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dev metrics: {'eval_loss': 0.4233614458876141, 'eval_acc': 0.8064916637105356}\n",
      "test metrics: {'eval_loss': 0.4265992186135716, 'eval_acc': 0.8016595289079229}\n"
     ]
    }
   ],
   "source": [
    "## Hypo_True\n",
    "save_model_predictions(\"dev-temporal-relation-data.tsv\", \n",
    "                        \"test-temporal-relation-data.tsv\",\n",
    "                        hypo_true,\n",
    "                       hypo_only=True,\n",
    "                        dev_dir = \"../../../data/dev/\",\n",
    "                        test_dir = \"../../../data/test/\",\n",
    "                        results_location=\"results/\")\n",
    "\n",
    "## Hypo_True\n",
    "save_model_predictions(\"dev-temporal-relation-data.tsv\", \n",
    "                        \"test-temporal-relation-data.tsv\",\n",
    "                        hypo_false,\n",
    "                       hypo_only=False,\n",
    "                        dev_dir = \"../../../data/dev/\",\n",
    "                        test_dir = \"../../../data/test/\",\n",
    "                        results_location=\"results/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TB-Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo_true = \"../../../saved_models/roberta-large/roberta-large_tbdense_lr_2e-05_wt_0.1_ws_122_hypo_only_True/checkpoint-1392/\"\n",
    "hypo_false = \"../../../saved_models/roberta-large/roberta-large_tbdense_lr_2e-05_wt_0.1_ws_122_hypo_only_False/checkpoint-2320/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path: ../../../saved_models/roberta-large/roberta-large_tbdense_lr_2e-05_wt_0.1_ws_122_hypo_only_True/checkpoint-1392/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are instantiating a Trainer but Tensorboard is not installed. You should consider installing it.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd45c44c53e49b2ac7ff4634aa1a3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=4.0, style=ProgressStyle(description_widâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidvash/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad72736d2fc0478181e5029ea490f82e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=8.0, style=ProgressStyle(description_widâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dev metrics: {'eval_loss': 0.44996563345193863, 'eval_acc': 0.6832460732984293}\n",
      "test metrics: {'eval_loss': 0.4395090714097023, 'eval_acc': 0.6882591093117408}\n",
      "Model path: ../../../saved_models/roberta-large/roberta-large_tbdense_lr_2e-05_wt_0.1_ws_122_hypo_only_False/checkpoint-2320/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are instantiating a Trainer but Tensorboard is not installed. You should consider installing it.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9fb946ca1745b4b9ef5f6188639b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=4.0, style=ProgressStyle(description_widâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4292eead381a45dcae3622d4467d4c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=8.0, style=ProgressStyle(description_widâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dev metrics: {'eval_loss': 0.9928825050592422, 'eval_acc': 0.8900523560209425}\n",
      "test metrics: {'eval_loss': 0.4440744537860155, 'eval_acc': 0.9460188933873145}\n"
     ]
    }
   ],
   "source": [
    "## Hypo_True\n",
    "save_model_predictions(\"dev-tbdense-data.tsv\", \n",
    "                        \"test-tbdense-data.tsv\",\n",
    "                        hypo_true,\n",
    "                       hypo_only=True,\n",
    "                        dev_dir = \"../../../data/dev/\",\n",
    "                        test_dir = \"../../../data/test/\",\n",
    "                        results_location=\"results/\")\n",
    "\n",
    "## Hypo_True\n",
    "save_model_predictions(\"dev-tbdense-data.tsv\", \n",
    "                        \"test-tbdense-data.tsv\",\n",
    "                        hypo_false,\n",
    "                       hypo_only=False,\n",
    "                        dev_dir = \"../../../data/dev/\",\n",
    "                        test_dir = \"../../../data/test/\",\n",
    "                        results_location=\"results/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TE3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo_true = \"../../../saved_models/roberta-large/roberta-large_te3_lr_2e-05_wt_0.1_ws_122_hypo_only_True/checkpoint-6435/\"\n",
    "hypo_false = \"../../../saved_models/roberta-large/roberta-large_te3_lr_2e-05_wt_0.1_ws_122_hypo_only_False/checkpoint-1287/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path: ../../../saved_models/roberta-large/roberta-large_te3_lr_2e-05_wt_0.1_ws_122_hypo_only_True/checkpoint-6435/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are instantiating a Trainer but Tensorboard is not installed. You should consider installing it.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e1ebbbae8d74546b8b4413ca4a2589d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=9.0, style=ProgressStyle(description_widâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidvash/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809d0c64b8de4753959034d1cc72c61b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=9.0, style=ProgressStyle(description_widâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dev metrics: {'eval_loss': 1.3485427896181743, 'eval_acc': 0.6602409638554216}\n",
      "test metrics: {'eval_loss': 1.3815964526600308, 'eval_acc': 0.6321942446043165}\n",
      "Model path: ../../../saved_models/roberta-large/roberta-large_te3_lr_2e-05_wt_0.1_ws_122_hypo_only_False/checkpoint-1287/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are instantiating a Trainer but Tensorboard is not installed. You should consider installing it.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f493f24a29c4c79baf70897cc47eaf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=9.0, style=ProgressStyle(description_widâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219329839de74990a5c419202e81b10e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=9.0, style=ProgressStyle(description_widâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dev metrics: {'eval_loss': 0.6901681356959872, 'eval_acc': 0.5403614457831325}\n",
      "test metrics: {'eval_loss': 0.6891425781779819, 'eval_acc': 0.5455635491606715}\n"
     ]
    }
   ],
   "source": [
    "## Hypo_True\n",
    "save_model_predictions(\"dev-tempeval3-data.tsv\", \n",
    "                        \"test-tempeval3-data.tsv\",\n",
    "                        hypo_true,\n",
    "                       hypo_only=True,\n",
    "                        dev_dir = \"../../../data/dev/\",\n",
    "                        test_dir = \"../../../data/test/\",\n",
    "                        results_location=\"results/\")\n",
    "\n",
    "## Hypo_True\n",
    "save_model_predictions(\"dev-tempeval3-data.tsv\", \n",
    "                        \"test-tempeval3-data.tsv\",\n",
    "                        hypo_false,\n",
    "                       hypo_only=False,\n",
    "                        dev_dir = \"../../../data/dev/\",\n",
    "                        test_dir = \"../../../data/test/\",\n",
    "                        results_location=\"results/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo_true = \"../../../saved_models/roberta-large/roberta-large_red_lr_2e-05_wt_0.1_ws_122_hypo_only_True/checkpoint-303/\"\n",
    "hypo_false = \"../../../saved_models/roberta-large/roberta-large_red_lr_2e-05_wt_0.1_ws_122_hypo_only_False/checkpoint-1515/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path: ../../../saved_models/roberta-large/roberta-large_red_lr_2e-05_wt_0.1_ws_122_hypo_only_True/checkpoint-303/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are instantiating a Trainer but Tensorboard is not installed. You should consider installing it.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178e3cd02b9a4bbabf9cf430c838d48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=1.0, style=ProgressStyle(description_widâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidvash/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195a08adda774dc1b3230171d7d11a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=2.0, style=ProgressStyle(description_widâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dev metrics: {'eval_loss': 0.6963768005371094, 'eval_acc': 0.5168918918918919}\n",
      "test metrics: {'eval_loss': 0.689303457736969, 'eval_acc': 0.5251141552511416}\n",
      "Model path: ../../../saved_models/roberta-large/roberta-large_red_lr_2e-05_wt_0.1_ws_122_hypo_only_False/checkpoint-1515/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are instantiating a Trainer but Tensorboard is not installed. You should consider installing it.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d6e6a4bcc547bcaa4a06db6c085c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=1.0, style=ProgressStyle(description_widâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b7ffed80604118853f0bb10aa984d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=2.0, style=ProgressStyle(description_widâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dev metrics: {'eval_loss': 0.9732860326766968, 'eval_acc': 0.8648648648648649}\n",
      "test metrics: {'eval_loss': 1.2793634533882141, 'eval_acc': 0.8059360730593608}\n"
     ]
    }
   ],
   "source": [
    "## Hypo_True\n",
    "save_model_predictions(\"dev-red-data.tsv\", \n",
    "                        \"test-red-data.tsv\",\n",
    "                        hypo_true,\n",
    "                       hypo_only=True,\n",
    "                        dev_dir = \"../../../data/dev/\",\n",
    "                        test_dir = \"../../../data/test/\",\n",
    "                        results_location=\"results/\")\n",
    "\n",
    "## Hypo_True\n",
    "save_model_predictions(\"dev-red-data.tsv\", \n",
    "                        \"test-red-data.tsv\",\n",
    "                        hypo_false,\n",
    "                       hypo_only=False,\n",
    "                        dev_dir = \"../../../data/dev/\",\n",
    "                        test_dir = \"../../../data/test/\",\n",
    "                        results_location=\"results/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temporal_nli",
   "language": "python",
   "name": "temporal_nli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
